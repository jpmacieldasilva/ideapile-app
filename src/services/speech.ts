import * as Speech from 'expo-speech';
import Voice from '@react-native-voice/voice';
import { Platform } from 'react-native';

// Interface para resultados de speech-to-text
export interface SpeechResult {
  text: string;
  confidence?: number;
}

// Configura√ß√µes padr√£o para speech
const SPEECH_CONFIG = {
  language: 'pt-BR', // Portugu√™s brasileiro
  maxResults: 1,
  partialResults: true,
};

// Classe para gerenciar funcionalidades de voz
class SpeechService {
  private isListening = false;
  private onResultCallback: ((result: SpeechResult) => void) | null = null;
  private onErrorCallback: ((error: string) => void) | null = null;

  constructor() {
    // S√≥ configurar callbacks do Voice se n√£o estiver na web (Expo Go)
    if (Platform.OS !== 'web') {
      try {
        Voice.onSpeechStart = this.onSpeechStart.bind(this);
        Voice.onSpeechRecognized = this.onSpeechRecognized.bind(this);
        Voice.onSpeechEnd = this.onSpeechEnd.bind(this);
        Voice.onSpeechError = this.onSpeechError.bind(this);
        Voice.onSpeechResults = this.onSpeechResults.bind(this);
        Voice.onSpeechPartialResults = this.onSpeechPartialResults.bind(this);
        Voice.onSpeechVolumeChanged = this.onSpeechVolumeChanged.bind(this);
      } catch (error) {
        console.warn('‚ö†Ô∏è Voice callbacks setup failed (provavelmente Expo Go):', error);
      }
    }
  }

  // Callbacks do Voice
  private onSpeechStart = (e: any) => {
    console.log('üé§ Speech recognition started');
    this.isListening = true;
  };

  private onSpeechRecognized = (e: any) => {
    console.log('üé§ Speech recognized');
  };

  private onSpeechEnd = (e: any) => {
    console.log('üé§ Speech recognition ended');
    this.isListening = false;
  };

  private onSpeechError = (e: any) => {
    console.error('‚ùå Speech recognition error:', e.error);
    this.isListening = false;
    if (this.onErrorCallback) {
      this.onErrorCallback(`Erro no reconhecimento: ${e.error?.message || e.error}`);
    }
  };

  private onSpeechResults = (e: any) => {
    console.log('‚úÖ Speech results:', e.value);
    if (e.value && e.value.length > 0 && this.onResultCallback) {
      const bestResult = e.value[0]; // Pegar o melhor resultado
      this.onResultCallback({
        text: bestResult,
        confidence: 0.95 // Voice n√£o fornece confidence, ent√£o estimamos
      });
    }
    this.isListening = false;
  };

  private onSpeechPartialResults = (e: any) => {
    console.log('üîÑ Partial results:', e.value);
    // Podemos mostrar resultados parciais se necess√°rio
  };

  private onSpeechVolumeChanged = (e: any) => {
    // console.log('üîä Volume changed:', e.value);
  };

  // Verificar se speech-to-text est√° dispon√≠vel
  async isAvailable(): Promise<boolean> {
    try {
      // Se estiver na web (Expo Go), retornar false mas n√£o dar erro
      if (Platform.OS === 'web') {
        console.log('üåê Running on web (Expo Go) - Voice not available');
        return false;
      }

      const available = await Voice.isAvailable();
      console.log('üé§ Speech recognition available:', available);
      return Boolean(available);
    } catch (error) {
      console.error('‚ùå Error checking speech availability:', error);
      return false;
    }
  }

  // Iniciar captura de voz REAL
  async startListening(
    onResult: (result: SpeechResult) => void,
    onError: (error: string) => void
  ): Promise<void> {
    try {
      if (this.isListening) {
        throw new Error('J√° est√° escutando');
      }

      // Verificar se est√° dispon√≠vel
      const available = await this.isAvailable();
      if (!available) {
        // Fallback para quando n√£o est√° dispon√≠vel (Expo Go, etc)
        console.log('üîÑ Using fallback speech simulation');
        this.simulateSpeechRecognition(onResult, onError);
        return;
      }

      // Configurar callbacks
      this.onResultCallback = onResult;
      this.onErrorCallback = onError;

      // Configura√ß√µes do reconhecimento
      const options = {
        'EXTRA_LANGUAGE_MODEL': 'LANGUAGE_MODEL_FREE_FORM',
        'EXTRA_CALLING_PACKAGE': 'com.wseen.wseen',
        'EXTRA_PARTIAL_RESULTS': true,
        'REQUEST_PERMISSIONS_AUTO': true,
        'EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS': 10000,
        'EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS': 1500,
        'EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS': 1500,
      };

      // Iniciar reconhecimento
      await Voice.start(SPEECH_CONFIG.language, options);
      console.log('üé§ Voice recognition started with language:', SPEECH_CONFIG.language);

    } catch (error) {
      console.error('‚ùå Error starting speech recognition:', error);
      this.isListening = false;
      this.onResultCallback = null;
      this.onErrorCallback = null;
      onError(error instanceof Error ? error.message : 'Erro ao iniciar reconhecimento de voz');
    }
  }

  // Parar captura de voz
  async stopListening(): Promise<void> {
    try {
      if (this.isListening) {
        // S√≥ chamar Voice.stop() se n√£o estiver na web
        if (Platform.OS !== 'web') {
          try {
            await Voice.stop();
            console.log('üõë Voice recognition stopped');
          } catch (error) {
            console.warn('‚ö†Ô∏è Voice stop failed (expected in Expo Go):', error);
          }
        } else {
          console.log('üõë [SIMULA√á√ÉO] Reconhecimento interrompido');
        }
      }
      this.isListening = false;
      this.onResultCallback = null;
      this.onErrorCallback = null;
    } catch (error) {
      console.error('‚ùå Error stopping speech recognition:', error);
      this.isListening = false;
      this.onResultCallback = null;
      this.onErrorCallback = null;
    }
  }

  // Verificar se est√° ouvindo
  getIsListening(): boolean {
    return this.isListening;
  }

  // Simula√ß√£o para quando Voice n√£o est√° dispon√≠vel (Expo Go)
  private simulateSpeechRecognition(
    onResult: (result: SpeechResult) => void,
    onError: (error: string) => void
  ): void {
    this.isListening = true;
    console.log('üé§ [SIMULA√á√ÉO] Iniciando reconhecimento de voz...');

    // Simular processo de captura de voz
    setTimeout(() => {
      if (this.isListening) {
        const simulatedTexts = [
          'Implementar autentica√ß√£o com biometria no aplicativo',
          'Criar uma funcionalidade de backup autom√°tico das ideias',
          'Desenvolver um sistema de categoriza√ß√£o inteligente',
          'Adicionar integra√ß√£o com calend√°rio para lembretes',
          'Criar modo escuro para o aplicativo',
          'Implementar sincroniza√ß√£o com nuvem',
          'Adicionar funcionalidade de compartilhamento de ideias',
          'Criar dashboard de analytics das ideias',
          'Implementar busca avan√ßada com filtros'
        ];
        
        const randomText = simulatedTexts[Math.floor(Math.random() * simulatedTexts.length)];
        
        onResult({
          text: `[DEMO] ${randomText}`,
          confidence: 0.92
        });

        this.isListening = false;
        console.log('‚úÖ [SIMULA√á√ÉO] Reconhecimento conclu√≠do');
      }
    }, 2500); // 2.5 segundos para simular tempo real
  }

  // Text-to-speech (ler texto em voz alta)
  async speak(text: string, options?: {
    language?: string;
    pitch?: number;
    rate?: number;
    volume?: number;
  }): Promise<void> {
    try {
      const speechOptions = {
        language: options?.language || 'pt-BR',
        pitch: options?.pitch || 1.0,
        rate: options?.rate || 0.8,
        volume: options?.volume || 1.0,
      };

      await Speech.speak(text, speechOptions);
      console.log('üîä Speaking text:', text.substring(0, 50) + '...');
    } catch (error) {
      console.error('‚ùå Error speaking text:', error);
      throw error;
    }
  }

  // Parar fala
  async stopSpeaking(): Promise<void> {
    try {
      await Speech.stop();
      console.log('üîá Stopped speaking');
    } catch (error) {
      console.error('‚ùå Error stopping speech:', error);
    }
  }

  // Verificar se est√° falando
  async isSpeaking(): Promise<boolean> {
    try {
      return await Speech.isSpeakingAsync();
    } catch (error) {
      console.error('‚ùå Error checking if speaking:', error);
      return false;
    }
  }

  // Listar idiomas dispon√≠veis
  async getAvailableLanguages(): Promise<string[]> {
    try {
      // Lista b√°sica de idiomas suportados
      return [
        'pt-BR', // Portugu√™s brasileiro
        'en-US', // Ingl√™s americano
        'es-ES', // Espanhol
        'fr-FR', // Franc√™s
        'de-DE', // Alem√£o
        'it-IT', // Italiano
        'ja-JP', // Japon√™s
        'ko-KR', // Coreano
        'zh-CN', // Chin√™s simplificado
      ];
    } catch (error) {
      console.error('‚ùå Error getting available languages:', error);
      return ['pt-BR'];
    }
  }

  // Configurar idioma padr√£o
  setDefaultLanguage(language: string): void {
    // Aqui poder√≠amos salvar nas configura√ß√µes
    console.log('üåê Default language set to:', language);
  }

  // Funcionalidade experimental: transcrever √°udio para ideias
  async transcribeAudioToIdea(audioUri?: string): Promise<SpeechResult> {
    try {
      // Verificar se temos uma URI de √°udio v√°lida
      if (!audioUri) {
        throw new Error('URI de √°udio n√£o fornecida');
      }

      console.log('üéµ Transcribing audio to idea...', audioUri);
      
      // Verificar se a OpenAI est√° configurada
      const { storage } = await import('./storage');
      const apiKey = await storage.getOpenAIKey();
      
      if (!apiKey) {
        throw new Error('Chave da OpenAI n√£o configurada. Configure nas configura√ß√µes.');
      }

      // Importar OpenAI dinamicamente
      const OpenAI = (await import('openai')).default;
      const openai = new OpenAI({
        apiKey,
        dangerouslyAllowBrowser: true,
      });

      // Ler o arquivo de √°udio
      const FileSystem = await import('expo-file-system');
      const audioData = await FileSystem.readAsStringAsync(audioUri, {
        encoding: FileSystem.EncodingType.Base64,
      });

      // Converter base64 para buffer
      const audioBuffer = Buffer.from(audioData, 'base64');

      // Fazer a transcri√ß√£o usando OpenAI Whisper
      const transcription = await openai.audio.transcriptions.create({
        file: new File([audioBuffer], 'audio.wav', { type: 'audio/wav' }),
        model: 'whisper-1',
        language: 'pt', // Portugu√™s
        response_format: 'text',
      });

      const transcribedText = transcription.toString().trim();

      if (!transcribedText) {
        throw new Error('Transcri√ß√£o retornou texto vazio');
      }

      console.log('‚úÖ Audio transcribed successfully:', transcribedText.substring(0, 100) + '...');
      
      return {
        text: transcribedText,
        confidence: 0.95 // Whisper tem alta precis√£o
      };
    } catch (error) {
      console.error('‚ùå Error transcribing audio:', error);
      
      // Fallback para simula√ß√£o se a transcri√ß√£o falhar
      if (error instanceof Error && error.message.includes('Chave da OpenAI')) {
        throw new Error('Configure sua chave da OpenAI nas configura√ß√µes para usar transcri√ß√£o de √°udio.');
      }
      
      // Simula√ß√£o como fallback
      console.log('üîÑ Using fallback transcription simulation');
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      return {
        text: 'Ideia transcrita de √°udio: Criar um aplicativo que use IA para organizar pensamentos e gerar insights autom√°ticos',
        confidence: 0.87
      };
    }
  }

  // Cleanup - limpar recursos
  async cleanup(): Promise<void> {
    try {
      await this.stopListening();
      await this.stopSpeaking();
      
      // Destruir o reconhecimento de voz apenas se n√£o estiver na web
      if (Platform.OS !== 'web') {
        try {
          await Voice.destroy();
        } catch (error) {
          console.warn('‚ö†Ô∏è Voice destroy failed (expected in Expo Go):', error);
        }
      }
      
      console.log('üßπ Speech service cleaned up');
    } catch (error) {
      console.error('‚ùå Error cleaning up speech service:', error);
    }
  }

  // M√©todo auxiliar: transcrever √°udio e criar ideia automaticamente
  async transcribeAndCreateIdea(audioUri: string): Promise<{ text: string; tags: string[] }> {
    try {
      console.log('üéµ Starting audio transcription and idea creation...');
      
      // Transcrever o √°udio
      const transcription = await this.transcribeAudioToIdea(audioUri);
      
      // Gerar tags automaticamente usando IA
      const { aiService } = await import('./ai');
      const { storage } = await import('./storage');
      
      let tags: string[] = [];
      
      try {
        const isConfigured = await aiService.isConfigured();
        if (isConfigured) {
          console.log('üè∑Ô∏è Generating tags for transcribed content...');
          tags = await aiService.generateTags(transcription.text);
        } else {
          console.log('‚ö†Ô∏è AI not configured, using basic tags');
          tags = ['√°udio', 'transcri√ß√£o', 'ideia'];
        }
      } catch (error) {
        console.error('‚ùå Error generating tags for transcription:', error);
        tags = ['√°udio', 'transcri√ß√£o', 'ideia'];
      }
      
      console.log('‚úÖ Transcription and tagging completed');
      return {
        text: transcription.text,
        tags
      };
    } catch (error) {
      console.error('‚ùå Error in transcribeAndCreateIdea:', error);
      throw error;
    }
  }
}

// Exportar inst√¢ncia singleton
export const speechService = new SpeechService();
export default speechService;
